name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  test:
    name: Test Suite
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        rust: [stable]
        include:
          - os: ubuntu-latest
            rust: beta
          - os: ubuntu-latest
            rust: nightly
    steps:
      - uses: actions/checkout@v4
        with:
          sparse-checkout: |
            src
            tests
            Cargo.toml
            Cargo.lock
            README.md
            Justfile
            .github
          sparse-checkout-cone-mode: true
      
      - name: Install Rust
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: ${{ matrix.rust }}
          components: rustfmt, clippy
      
      - name: Cache cargo registry
        uses: actions/cache@v4
        with:
          path: ~/.cargo/registry
          key: ${{ runner.os }}-cargo-registry-${{ hashFiles('**/Cargo.lock') }}
      
      - name: Cache cargo index
        uses: actions/cache@v4
        with:
          path: ~/.cargo/git
          key: ${{ runner.os }}-cargo-index-${{ hashFiles('**/Cargo.lock') }}
      
      - name: Cache cargo build
        uses: actions/cache@v4
        with:
          path: target
          key: ${{ runner.os }}-cargo-build-target-${{ matrix.rust }}-${{ hashFiles('**/Cargo.lock') }}
      
      - name: Check formatting
        run: cargo fmt --all -- --check
        if: matrix.rust == 'stable' && matrix.os == 'ubuntu-latest'
      
      - name: Run clippy
        run: cargo clippy --all-targets --all-features -- -D warnings
        if: matrix.rust == 'stable'
      
      - name: Build
        run: cargo build --verbose
      
      - name: Run tests
        run: cargo test --verbose
      
      - name: Build release
        run: cargo build --release --verbose
        if: matrix.rust == 'stable'

  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          sparse-checkout: |
            src
            tests
            Cargo.toml
            Cargo.lock
            README.md
            Justfile
            .github
          sparse-checkout-cone-mode: true
      
      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
      
      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
      
      - name: Run integration tests
        run: |
          cargo test --test integration_* --verbose
      
      - name: Test CLI commands
        run: |
          cargo build --release
          ./target/release/cli-rag --version
          ./target/release/cli-rag init --print-template > /tmp/test-template.toml
          ./target/release/cli-rag completions bash > /tmp/test-completions.bash
          ./target/release/cli-rag completions zsh > /tmp/test-completions.zsh

      - name: Watch NDJSON handshake
        run: |
          set -euo pipefail
          WORKDIR=$(mktemp -d)
          export WORKDIR
          mkdir -p "$WORKDIR/notes"
          cat > "$WORKDIR/.cli-rag.toml" <<EOF
          bases = [
            '$WORKDIR/notes'
          ]

          [[schema]]
          name = "ADR"
          file_patterns = ["ADR-*.md"]
          unknown_policy = "ignore"
          EOF
          python - <<'PY'
          import json, os, subprocess, sys
          workdir = os.environ['WORKDIR']
          p = subprocess.Popen([
          './target/release/cli-rag', '--config', f'{workdir}/.cli-rag.toml', 'watch', '--debounce-ms', '200', '--dry-run', '--json'
          ], stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, text=True)
          try:
              line = p.stdout.readline().strip()
              obj = json.loads(line)
              assert obj.get('event') == 'watch_start', obj
              assert obj.get('protocolVersion') == 1, obj
          finally:
              p.kill()
          print('watch handshake OK')
          PY

  msrv:
    name: Minimum Supported Rust Version
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          sparse-checkout: |
            src
            tests
            Cargo.toml
            Cargo.lock
            README.md
            Justfile
            .github
          sparse-checkout-cone-mode: true
      
      - name: Extract MSRV
        id: msrv
        run: |
          msrv=$(grep -E "^rust-version" Cargo.toml | grep -oE "[0-9]+\.[0-9]+\.[0-9]+")
          if [ -z "$msrv" ]; then
            echo "msrv=1.70.0" >> $GITHUB_OUTPUT
          else
            echo "msrv=$msrv" >> $GITHUB_OUTPUT
          fi
      
      - name: Install MSRV toolchain
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: ${{ steps.msrv.outputs.msrv }}
      
      - name: Check MSRV
        run: |
          rm -f Cargo.lock
          cargo check --all-features

  contracts:
    name: Contracts Compliance (Phase 1)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install Rust
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy
      - name: Build release
        run: cargo build --release --verbose
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install jsonschema
        run: |
          python -m pip install --upgrade pip
          python -m pip install jsonschema
      - name: Create fixture repo
        id: fx
        run: |
          set -euo pipefail
          WORKDIR=$(mktemp -d)
          echo "workdir=$WORKDIR" >> $GITHUB_OUTPUT
          mkdir -p "$WORKDIR/notes"
          # minimal config using the fixture base
          BASE="$WORKDIR/notes"
          cat > "$WORKDIR/.cli-rag.toml" <<EOF
          [config]
          config_version = "1.2"

          [config.scan]
          filepaths = [
            "$BASE"
          ]
          index_path = "index/adr-index.json"
          index_strategy = "content"
          ignore_globs = ["**/tmp/**"]

          [config.authoring]
          editor = "nvim"

          [config.graph]
          depth = 2
          include_bidirectional = true

          [config.templates]
          import = []

          [[schema]]
          name = "ADR"
          file_patterns = ["ADR-*.md"]
          unknown_policy = "ignore"
          [schema.new]
          id_generator = { strategy = "increment", prefix = "ADR-", padding = 3 }
          filename_template = "{{id}}-{{title|kebab-case}}.md"

          [[schema]]
          name = "IMP"
          file_patterns = ["IMP-*.md"]
          unknown_policy = "ignore"
          [schema.new]
          id_generator = { strategy = "datetime", prefix = "IMP-" }
          filename_template = "{{now|date:\"%Y-%m-%d\"}}-{{title|snake_case}}.md"
          EOF
      - name: Validate info JSON matches schema
        run: |
          SCHEMA="contracts/v1/cli/info.schema.json"
          OUT=$(./target/release/cli-rag --config "${{ steps.fx.outputs.workdir }}/.cli-rag.toml" info --format json)
          python - "$SCHEMA" "$OUT" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, data_str = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.loads(data_str)
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          print("info.json OK")
          PY
      - name: Validate validate --dry-run JSON matches schema
        run: |
          SCHEMA="contracts/v1/cli/validate_result.schema.json"
          OUT=$(./target/release/cli-rag --config "${{ steps.fx.outputs.workdir }}/.cli-rag.toml" validate --format json --dry-run)
          python - "$SCHEMA" "$OUT" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, data_str = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.loads(data_str)
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          print("validate(dry).json OK")
          PY
      - name: Validate resolved config snapshot
        run: |
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          ./target/release/cli-rag --config "$WORKDIR/.cli-rag.toml" validate --format json >/dev/null
          test -f "$WORKDIR/.cli-rag/resolved.json"
          SCHEMA="contracts/v1/config/resolved_config.json"
          python - "$SCHEMA" "$WORKDIR/.cli-rag/resolved.json" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, resolved_path = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.load(open(resolved_path))
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          print("resolved.json OK")
          PY

      - name: Nested user_config acceptance (IMP-014)
        run: |
          set -euo pipefail
          WORKDIR=$(mktemp -d)
          mkdir -p "$WORKDIR/notes"
          cat > "$WORKDIR/.cli-rag.toml" <<EOF
          [config]
          config_version = "1.2"

          [config.scan]
          filepaths = [
            "$WORKDIR/notes"
          ]
          index_path = "alt/index.json"
          ignore_globs = ["**/tmp/**"]

          [config.graph]
          depth = 3
          include_bidirectional = false

          [config.templates]
          import = [".cli-rag/templates/ADR.toml"]
          EOF
          ./target/release/cli-rag --config "$WORKDIR/.cli-rag.toml" validate --format json >/dev/null
          test -f "$WORKDIR/.cli-rag/resolved.json"
          SCHEMA="contracts/v1/config/resolved_config.json"
          python - "$SCHEMA" "$WORKDIR/.cli-rag/resolved.json" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, resolved_path = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.load(open(resolved_path))
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          assert data.get('graph',{}).get('depth') == 3
          assert data.get('graph',{}).get('includeBidirectional') is False
          assert data.get('configVersion') == '1.2'
          assert data.get('scan',{}).get('indexPath','').endswith('alt/index.json')
          print('nested user_config acceptance OK')
          PY

      - name: Lua overlays smoke (enabled vs --no-lua)
        run: |
          set -euo pipefail
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          export WORKDIR
          CFG="$WORKDIR/.cli-rag.toml"
          # Create a repo overlay that sets a sentinel value
          cat > "$WORKDIR/.cli-rag.lua" <<'LUA'
          return {
            sentinel = 42
          }
          LUA
          # Run validate to write resolved.json with overlays.enabled true
          ./target/release/cli-rag --config "$CFG" validate --format json >/dev/null
          test -f "$WORKDIR/.cli-rag/resolved.json"
          python - <<'PY'
          import json, os
          workdir = os.environ['WORKDIR']
          resolved_path = os.path.join(workdir, '.cli-rag', 'resolved.json')
          data = json.load(open(resolved_path))
          overlays = data.get('overlays', {})
          assert overlays.get('enabled') is True
          expected_repo = os.path.join(workdir, '.cli-rag.lua')
          assert overlays.get('repoPath') == expected_repo, overlays
          assert overlays.get('userPath') is None
          print('overlays enabled OK')
          PY
          # Now run with --no-lua to disable overlays and rewrite snapshot
          ./target/release/cli-rag --config "$CFG" --no-lua validate --format json >/dev/null
          python - <<'PY'
          import json, os
          workdir = os.environ['WORKDIR']
          resolved_path = os.path.join(workdir, '.cli-rag', 'resolved.json')
          data = json.load(open(resolved_path))
          overlays = data.get('overlays', {})
          assert overlays.get('enabled') is False
          assert overlays.get('repoPath') is None
          assert overlays.get('userPath') is None
          print('overlays disabled OK')
          PY
      - name: ai new start/cancel smoke
        run: |
          set -euo pipefail
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          CFG="$WORKDIR/.cli-rag.toml"
          START_JSON=$(./target/release/cli-rag --config "$CFG" ai new start --schema ADR --title "CI Draft")
          export START_JSON
          DRAFT_ID=$(
            python - <<'PY'
          import json, os
          from jsonschema import validate, Draft202012Validator
          
          schema = json.load(open("contracts/v1/cli/ai_new_start.schema.json"))
          Draft202012Validator.check_schema(schema)
          data = json.loads(os.environ["START_JSON"])
          validate(instance=data, schema=schema)
          print(data["draftId"])
          PY
          )
          LIST_JSON=$(./target/release/cli-rag --config "$CFG" ai new list)
          export LIST_JSON
          python - <<'PY'
          import json, os
          from jsonschema import validate, Draft202012Validator
          
          schema = json.load(open("contracts/v1/cli/ai_new_list.schema.json"))
          Draft202012Validator.check_schema(schema)
          data = json.loads(os.environ["LIST_JSON"])
          validate(instance=data, schema=schema)
          assert data["drafts"], "expected at least one draft in list"
          PY
          CANCEL_JSON=$(./target/release/cli-rag --config "$CFG" ai new cancel --draft "$DRAFT_ID")
          export CANCEL_JSON
          python - <<'PY'
          import json, os
          from jsonschema import validate, Draft202012Validator
          
          schema = json.load(open("contracts/v1/cli/ai_new_cancel.schema.json"))
          Draft202012Validator.check_schema(schema)
          data = json.loads(os.environ["CANCEL_JSON"])
          validate(instance=data, schema=schema)
          assert data.get("ok") is True
          PY
          LIST_JSON=$(./target/release/cli-rag --config "$CFG" ai new list)
          export LIST_JSON
          python - <<'PY'
          import json, os
          from jsonschema import validate, Draft202012Validator
          
          schema = json.load(open("contracts/v1/cli/ai_new_list.schema.json"))
          Draft202012Validator.check_schema(schema)
          data = json.loads(os.environ["LIST_JSON"])
          validate(instance=data, schema=schema)
          assert not data["drafts"], "expected drafts list to be empty after cancel"
          PY
          unset START_JSON CANCEL_JSON LIST_JSON
      - name: Validate unified index JSON matches schema
        run: |
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          INDEX_PATH="$WORKDIR/index/adr-index.json"
          test -f "$INDEX_PATH"
          SCHEMA="contracts/v1/index/index.schema.json"
          python - "$SCHEMA" "$INDEX_PATH" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, index_path = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.load(open(index_path))
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          print("unified index OK")
          PY

      - name: Validate ai-index-plan JSON matches schema
        run: |
          set -euo pipefail
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          CFG="$WORKDIR/.cli-rag.toml"
          PLAN="$WORKDIR/plan.json"
          # Ensure unified index exists
          ./target/release/cli-rag --config "$CFG" validate --format json >/dev/null
          ./target/release/cli-rag --config "$CFG" ai-index-plan --min-cluster-size 1 --output "$PLAN"
          SCHEMA="contracts/v1/cli/ai_index_plan.schema.json"
          python - "$SCHEMA" "$PLAN" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, plan_path = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.load(open(plan_path))
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          assert data.get('version') == 1
          assert isinstance(data.get('clusters'), list)
          print("ai_index_plan.json OK")
          PY

      - name: Validate ai-index-apply report (dry-run) matches schema
        run: |
          set -euo pipefail
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          CFG="$WORKDIR/.cli-rag.toml"
          PLAN="$WORKDIR/plan.json"
          OUT=$(./target/release/cli-rag --config "$CFG" ai-index-apply --from "$PLAN" --dry-run)
          SCHEMA="contracts/v1/cli/ai_index_apply_report.schema.json"
          python - "$SCHEMA" "$OUT" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, data_str = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.loads(data_str)
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          assert data.get('ok') is True
          assert data.get('written', {}).get('cache') is True
          print("ai_index_apply(dry).json OK")
          PY

      - name: Validate ai-index-apply non-dry run writes cache and tags
        run: |
          set -euo pipefail
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          NOTES="$WORKDIR/notes"
          CFG="$WORKDIR/.cli-rag.toml"
          # Create two connected notes with tags fields for tag writes
          cat > "$NOTES/ADR-010.md" <<'MD'
          ---
          id: ADR-010
          tags: []
          status: draft
          depends_on: [ADR-011]
          ---

          # ADR-010
          MD
          cat > "$NOTES/ADR-011.md" <<'MD'
          ---
          id: ADR-011
          tags: []
          status: draft
          depends_on: []
          ---

          # ADR-011
          MD
          # Build index and plan
          ./target/release/cli-rag --config "$CFG" validate --format json >/dev/null
          PLAN="$WORKDIR/plan_apply.json"
          ./target/release/cli-rag --config "$CFG" ai-index-plan --min-cluster-size 2 --output "$PLAN"
          # Inject a label and remove tags on first cluster to trigger derivation
          python - "$PLAN" <<'PY'
          import json,sys
          p=sys.argv[1]
          obj=json.load(open(p))
          if obj['clusters']:
              c0=obj['clusters'][0]
              c0['label']='retrieval systems'
              if 'tags' in c0: del c0['tags']
          open(p,'w').write(json.dumps(obj))
          PY
          # Apply with frontmatter writes; capture JSON report to file
          REPORT="$WORKDIR/apply_report.json"
          ./target/release/cli-rag --config "$CFG" ai-index-apply --from "$PLAN" --write-frontmatter > "$REPORT"
          SCHEMA="contracts/v1/cli/ai_index_apply_report.schema.json"
          python - "$SCHEMA" "$REPORT" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, report_path = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.load(open(report_path))
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          assert data.get('ok') is True
          assert data.get('written',{}).get('cache') is True
          assert data.get('written',{}).get('frontmatter') is True
          assert (data.get('membersTagged') or 0) >= 1
          print('ai_index_apply(non-dry) OK')
          PY
          test -f "$WORKDIR/.cli-rag/cache/ai-index.json"

      - name: Validate search JSON matches schema (note)
        run: |
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          NOTES="$WORKDIR/notes"
          CFG="$WORKDIR/.cli-rag.toml"
          # Write a simple ADR to search for
          cat > "$NOTES/ADR-100.md" <<'MD'
          ---
          id: ADR-100
          tags: [x]
          status: draft
          depends_on: []
          ---

          # ADR-100: Title
          MD
          # (Schemas are already defined in the fixture config)
          # Rebuild index to include new files
          ./target/release/cli-rag --config "$CFG" validate --format json >/dev/null
          OUT=$(./target/release/cli-rag --config "$CFG" search -q ADR-100 --format json)
          SCHEMA="contracts/v1/cli/search_result.schema.json"
          python - "$SCHEMA" "$OUT" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, data_str = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.loads(data_str)
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          assert any(item.get('kind')=='note' for item in data.get('results', []))
          print("search(note).json OK")
          PY

      - name: Validate search JSON matches schema (todo + kanban)
        run: |
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          NOTES="$WORKDIR/notes"
          CFG="$WORKDIR/.cli-rag.toml"
          # Add a note with a TODO in body and kanban in frontmatter
          cat > "$NOTES/ADR-101.md" <<'MD'
          ---
          id: ADR-101
          tags: [x]
          status: draft
          depends_on: []
          kanban_status: doing
          kanban_statusline: In progress
          due_date: 2026-01-01
          ---

          # ADR-101: Title

          - [ ] Task one
          MD
          # Rebuild index to include new files
          ./target/release/cli-rag --config "$CFG" validate --format json >/dev/null
          OUT=$(./target/release/cli-rag --config "$CFG" search -q ADR-101 --kind kanban,todo --format json)
          SCHEMA="contracts/v1/cli/search_result.schema.json"
          python - "$SCHEMA" "$OUT" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, data_str = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.loads(data_str)
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          items = data.get('results', [])
          assert any(item.get('kind')=='todo' for item in items)
          assert any(item.get('kind')=='kanban' for item in items)
          print("search(gtd).json OK")
          PY

      - name: Validate graph JSON matches schema (depends_on)
        run: |
          set -euo pipefail
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          NOTES="$WORKDIR/notes"
          CFG="$WORKDIR/.cli-rag.toml"
          # Write minimal fixture
          cat > "$NOTES/ADR-002.md" <<'MD'
          ---
          id: ADR-002
          tags: [x]
          status: draft
          depends_on: []
          ---

          # ADR-002: Title
          MD
          cat > "$NOTES/ADR-001.md" <<'MD'
          ---
          id: ADR-001
          tags: [x]
          status: draft
          depends_on: ["ADR-002"]
          ---

          # ADR-001: Title
          MD
          # (Schemas are already defined in the fixture config)
          # Rebuild index to include new files
          ./target/release/cli-rag --config "$CFG" validate --format json >/dev/null
          # Run graph
          OUT=$(./target/release/cli-rag --config "$CFG" graph --id ADR-001 --graph-format json)
          SCHEMA="contracts/v1/cli/graph.schema.json"
          python - "$SCHEMA" "$OUT" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, data_str = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.loads(data_str)
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          assert any(e.get('from')=='ADR-001' and e.get('to')=='ADR-002' and e.get('kind')=='depends_on' for e in data.get('edges', []))
          print("graph.json OK")
          PY

      - name: Validate path JSON matches schema (depends_on)
        run: |
          set -euo pipefail
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          CFG="$WORKDIR/.cli-rag.toml"
          # Ensure index includes ADR-001/ADR-002
          ./target/release/cli-rag --config "$CFG" validate --format json >/dev/null
          OUT=$(./target/release/cli-rag --config "$CFG" path --from ADR-001 --to ADR-002 --format json)
          SCHEMA="contracts/v1/cli/path.schema.json"
          python - "$SCHEMA" "$OUT" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, data_str = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.loads(data_str)
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          assert data.get('ok') is True
          print("path(depends_on).json OK")
          PY

      - name: Validate path JSON matches schema (mentions with locations)
        run: |
          set -euo pipefail
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          NOTES="$WORKDIR/notes"
          CFG="$WORKDIR/.cli-rag.toml"
          cat > "$NOTES/ADR-029.md" <<'MD'
          ---
          id: ADR-029
          tags: [x]
          status: draft
          depends_on: []
          ---

          # ADR-029: Title
          MD
          cat > "$NOTES/IMP-006.md" <<'MD'
          ---
          id: IMP-006
          tags: [x]
          status: draft
          depends_on: []
          ---

          # IMP-006: Title

          This mentions [[ADR-029]] here.
          MD
          cat > "$NOTES/ADR-024.md" <<'MD'
          ---
          id: ADR-024
          tags: [x]
          status: draft
          depends_on: ["IMP-006"]
          ---

          # ADR-024: Title
          MD
          # (Schemas are already defined in the fixture config)
          # Rebuild index to include new files
          ./target/release/cli-rag --config "$CFG" validate --format json >/dev/null
          OUT=$(./target/release/cli-rag --config "$CFG" path --from ADR-024 --to ADR-029 --format json)
          SCHEMA="contracts/v1/cli/path.schema.json"
          python - "$SCHEMA" "$OUT" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, data_str = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.loads(data_str)
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          # Has a mentions edge with at least one location
          assert any(e.get('kind')=='mentions' and isinstance(e.get('locations'), list) and len(e['locations'])>0 for e in data.get('edges', []))
          print("path(mentions).json OK")
          PY

      - name: New authoring acceptance (IMP-015)
        run: |
          set -euo pipefail
          WORKDIR=$(mktemp -d)
          export WORKDIR
          NOTES="$WORKDIR/notes"
          mkdir -p "$NOTES"
          CFG="$WORKDIR/.cli-rag.toml"
          cat > "$CFG" <<EOF
          bases = [
            "$NOTES"
          ]

          [[schema]]
          name = "RFC"
          file_patterns = ["RFC-*.md"]
          [schema.new]
          id_generator = { strategy = "increment", prefix = "RFC-", padding = 4 }

          [[schema]]
          name = "IMP"
          file_patterns = ["IMP-*.md"]
          [schema.new]
          id_generator = { strategy = "datetime", prefix = "IMP-" }

          [[schema]]
          name = "UID"
          file_patterns = ["UID-*.md"]
          [schema.new]
          id_generator = { strategy = "uuid", prefix = "UID-" }
          EOF
          # Build release binary if not present
          test -x ./target/release/cli-rag || cargo build --release
          # increment strategy
          ./target/release/cli-rag --config "$CFG" new --schema RFC --title "Spec One"
          test -f "$NOTES/RFC-0001.md"
          # datetime strategy
          ./target/release/cli-rag --config "$CFG" new --schema IMP --title "Time Based"
          ls "$NOTES" | grep -E '^IMP-[0-9]{14}\.md$'
          # uuid strategy
          ./target/release/cli-rag --config "$CFG" new --schema UID --title "Uuid Based"
          ls "$NOTES" | grep -E '^UID-[0-9a-f]{32}\.md$'
          # filename template filters via CLI
          TS=$(date +%Y-%m)
          ./target/release/cli-rag --config "$CFG" new --schema RFC --title "Hello Filters" --filename-template '{{now|date:"%Y-%m"}}-{{title|snake_case}}.md'
          test -f "$NOTES/$TS-hello_filters.md"
          # Validate repository remains healthy
          ./target/release/cli-rag --config "$CFG" validate --format json >/dev/null

      - name: Validate ai get JSON matches schema
        run: |
          set -euo pipefail
          WORKDIR="${{ steps.fx.outputs.workdir }}"
          NOTES="$WORKDIR/notes"
          CFG="$WORKDIR/.cli-rag.toml"
          # Add a simple ADR
          cat > "$NOTES/ADR-150.md" <<'MD'
          ---
          id: ADR-150
          tags: [x]
          status: draft
          depends_on: []
          ---

          # ADR-150: Title

          Body
          MD
          # (Schemas are already defined in the fixture config)
          # Rebuild index to include new files
          ./target/release/cli-rag --config "$CFG" validate --format json >/dev/null
          OUT=$(./target/release/cli-rag --config "$CFG" get --id ADR-150 --format json)
          SCHEMA="contracts/v1/cli/ai_get.schema.json"
          python - "$SCHEMA" "$OUT" <<'PY'
          import sys, json
          from jsonschema import validate, Draft202012Validator
          schema_path, data_str = sys.argv[1], sys.argv[2]
          schema = json.load(open(schema_path))
          data = json.loads(data_str)
          Draft202012Validator.check_schema(schema)
          validate(instance=data, schema=schema)
          assert data.get('protocolVersion') == 1
          assert data.get('retrievalVersion') == 1
          print("ai_get.json OK")
          PY
